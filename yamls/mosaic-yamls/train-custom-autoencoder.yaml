name: train-custom-autoencoder
image: mosaicml/pytorch_vision:2.0.1_cu118-python3.10-ubuntu20.04
compute:
  gpus: # Number of GPUs to use

  ## These configurations are optional
  # cluster: TODO # Name of the cluster to use for this run
  # gpu_type: a100_40gb # Type of GPU to use.
scheduling:
    resumable: true
    priority: medium # Run prioriy
integrations:
  - integration_type: "git_repo"
    git_repo: mosaicml/diffusion
    git_branch: main
    pip_install: .[all]
  - integration_type: "wandb"
    project: # Insert wandb project name
    entity: # Insert wandb entity name
command: |
  cd diffusion
  HYDRA_FULL_ERROR=1 composer run.py --config-path /mnt/config --config-name parameters
parameters:
  name:  # Insert wandb run name
  project:  # Insert wandb project name
  batch_size: 256 # Global train batch size, adjust as needed
  image_size: 256 # Size of images to use in training
  seed: 17
  eval_first: true # Runs eval before starting training
  model:
    _target_: diffusion.models.models.build_autoencoder
    kl_divergence_weight: 0.1 # Loss weight for the VAE KL divergence term, adjust as needed
    lpips_weight: 1.0 # Loss weight for LPIPS loss, adjust as needed
    discriminator_weight: 0.1 # Loss weight for discriminator, adjust as needed
    zero_init_last: true # Whether to initialize the last conv layer in residual blocks to zero
    use_attention: false # Whether to use attention at the autoencoder bottleneck
    latent_channels: 4 # The number of latent channels
  dataset:
    train_batch_size: ${batch_size}
    eval_batch_size: ${batch_size}
    train_dataset:
      # Currently we are using the image_caption dataloader, though captions are not necessary for the autoencoder.
      _target_: diffusion.datasets.image_caption.build_streaming_image_caption_dataloader
      remote: # Path(s) to object store bucket for training data
      local: # Path(s) to local training dataset cache
      batch_size: ${batch_size}
      caption_drop_prob: 0.1
      resize_size: ${image_size}
      image_key: image # Image key in the train dataset
      caption_key: caption # Caption key in the train dataset
      crop_type: random
      dataloader_kwargs:
        drop_last: true
        num_workers: 8
        prefetch_factor: 2
        persistent_workers: true
        pin_memory: true
      streaming_kwargs:
        shuffle: true
        download_timeout: 300
        num_canonical_nodes: 1
    eval_dataset:
      _target_: diffusion.datasets.image_caption.build_streaming_image_caption_dataloader
      remote: # Path(s) to object store bucket for eval data
      local: # Path(s) to local eval dataset cache
      batch_size: ${batch_size}
      resize_size: ${image_size}
      caption_drop_prob: 0.0
      image_key: image # Image key in the eval dataset
      caption_key: caption # Caption key in the eval dataset
      dataloader_kwargs:
        drop_last: true
        num_workers: 8
        prefetch_factor: 2
        persistent_workers: true
        pin_memory: true
      streaming_kwargs:
        shuffle: false
        download_timeout: 300
        num_canonical_nodes: 1
  optimizer:
    _target_: torch.optim.AdamW
  autoencoder_optimizer: # Optimizer for the autoencoder
    lr: 4.5e-5
    weight_decay: 0.01
    betas:
    - 0.9
    - 0.95
    eps: 1.0e-08
  discriminator_optimizer: # Optimizer for the discriminator, if one wants different params for it
    lr: 4.5e-5
    weight_decay: 0.01
    betas:
    - 0.9
    - 0.95
    eps: 1.0e-08
  scheduler:
    _target_: composer.optim.CosineAnnealingWithWarmupScheduler
    t_warmup: 100ba # Warmup iterations, adjust as needed
  logger:
    wandb:
      _target_: composer.loggers.wandb_logger.WandBLogger
      name: ${name}
      project: ${project}
      group: ${name}
  callbacks:
    speed_monitor:
      _target_: composer.callbacks.speed_monitor.SpeedMonitor
      window_size: 10
    lr_monitor:
      _target_: composer.callbacks.lr_monitor.LRMonitor
    memory_monitor:
      _target_: composer.callbacks.memory_monitor.MemoryMonitor
    runtime_estimator:
      _target_: composer.callbacks.runtime_estimator.RuntimeEstimator
    latent_statistics_logger:
      _target_: diffusion.callbacks.log_latent_statistics.LogLatentStatistics # Useful to track scale of latents during training
    image_logger:
      _target_: diffusion.callbacks.log_diffusion_images.LogAutoencoderImages # Logging callback for autoencoder reconstructions
      max_images: 20
  algorithms:
    discriminator_schedule: # This enables one to start the discriminator later in training
      _target_: diffusion.algorithms.DiscriminatorSchedule
      start_iteration: 0ba # Adjust as needed, 0ba means start at the beginning of training
  trainer:
    _target_: composer.Trainer
    device: gpu
    max_duration: 1ep # Adust as needed
    eval_interval: 1000ba # Adjust as needed
    device_train_microbatch_size: 16 # Adjust as needed
    run_name: ${name}
    seed: ${seed}
    save_folder:  # Insert path to save folder or bucket
    save_interval: 10000ba # Adjust as needed
    save_overwrite: false
    autoresume: true
